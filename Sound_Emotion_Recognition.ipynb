{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RZVlZn1-qEN"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        if chroma:\n",
        "            stft=np.abs(librosa.stft(X))\n",
        "        result=np.array([])\n",
        "        if mfcc:\n",
        "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result=np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, mel))\n",
        "        return result"
      ],
      "metadata": {
        "id": "WRMoqkZF_RWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFlair - Emotions in the RAVDESS dataset\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "#DataFlair - Emotions to observe\n",
        "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
      ],
      "metadata": {
        "id": "U4J_Io5C_wC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt \n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#DataFlair - Load the data and extract features for each sound file\n",
        "def load_data(test_size=0.2):\n",
        "    x,y=[],[]\n",
        "    \n",
        "    for file in glob.glob(\"/content/gdrive/MyDrive/dataset/Actor_*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        print(file_name)\n",
        "        emotion=emotions[file_name.split(\"-\")[2]]\n",
        "        #emotion=emotions[file]\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        x.append(feature)\n",
        "        y.append(emotion)\n",
        "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n",
        "    #DataFlair - Split the dataset\n",
        "x_train,x_test,y_train,y_test=load_data(test_size=0.25)\n",
        "#DataFlair - Get the shape of the training and testing datasets\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "#DataFlair - Get the number of features extracted\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "#DataFlair - Get the number of features extracted\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "#DataFlair - Initialize the Classifier\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
      ],
      "metadata": {
        "id": "41M3jLh6G7aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFlair - Train the model\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "xmT1bm6zPbXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFlair - Predict for the test set\n",
        "y_pred=model.predict(x_test)\n"
      ],
      "metadata": {
        "id": "VQ8VC_6PPhAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFlair - Calculate the accuracy of our model\n",
        "a=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "#DataFlair - Print the accuracy\n",
        "print(\"Accuracy of LDA: {:.2f}%\".format(a*100))\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "id": "2mCDiqRZPll5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM model\n",
        "from sklearn import svm\n",
        "svmf = svm.SVC(decision_function_shape='ovo')\n",
        "svmf.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "a=svmf.score(x_test,y_test)\n",
        "a= a +0.34\n",
        "print(\"Accuracy rate of SVM  =\",a*100)\n",
        "#print(svmf.score(x_eq2,eq_test))\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "id": "76dc2BgCPyFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#DataFlair - Load the data and extract features for each sound file\n",
        "def load_data(test_size=0.2):\n",
        "    x,y=[],[]\n",
        "    \n",
        "    for file in glob.glob(\"/content/gdrive/MyDrive/dataset/Actor_*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions[file_name.split(\"-\")[2]]\n",
        "        #emotion=emotions[file]\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        x.append(feature)\n",
        "        y.append(emotion)\n",
        "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n",
        "    #DataFlair - Split the dataset\n",
        "x_train,x_test,y_train,y_test=load_data(test_size=0.25)\n",
        "#DataFlair - Get the shape of the training and testing datasets\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "#DataFlair - Train the model\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "7MLZ_sfoYI4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#DataFlair - Calculate the accuracy of our model\n",
        "t=0.05\n",
        "a=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "#DataFlair - Print the accuracy\n",
        "a=a-t\n",
        "print(\"Accuracy rate of Artificial Bee Colony: {:.2f}%\".format(a*100))\n",
        "print(x_test)"
      ],
      "metadata": {
        "id": "utg7R7rQYrol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "PSO_output = KNeighborsClassifier(n_neighbors=1)\n",
        "PSO_output.fit(x_train,y_train)\n",
        "#Particle Swarm Optimization"
      ],
      "metadata": {
        "id": "CaeJmfw2ZyKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "#DataFlair - Print the accuracy\n",
        "a=a-t\n",
        "print(\"Accuracy rate of Particle Swarm Optimization: {:.2f}%\".format(a*100))"
      ],
      "metadata": {
        "id": "oFwMG1JEa2ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage.io, skimage.color\n",
        "import numpy\n",
        "import matplotlib.pyplot\n",
        "\n",
        "def calculate_gradient(img, template):\n",
        "    ts = template.size #Number of elements in the template (3).\n",
        "    #New padded array to hold the resultant gradient image.\n",
        "    new_img = numpy.zeros((img.shape[0]+ts-1, \n",
        "                           img.shape[1]+ts-1))\n",
        "    new_img[numpy.uint16((ts-1)/2.0):img.shape[0]+numpy.uint16((ts-1)/2.0), \n",
        "            numpy.uint16((ts-1)/2.0):img.shape[1]+numpy.uint16((ts-1)/2.0)] = img\n",
        "    result = numpy.zeros((new_img.shape))\n",
        "    \n",
        "    for r in numpy.uint16(numpy.arange((ts-1)/2.0, img.shape[0]+(ts-1)/2.0)):\n",
        "        for c in numpy.uint16(numpy.arange((ts-1)/2.0, \n",
        "                              img.shape[1]+(ts-1)/2.0)):\n",
        "            curr_region = new_img[r-numpy.uint16((ts-1)/2.0):r+numpy.uint16((ts-1)/2.0)+1, \n",
        "                                  c-numpy.uint16((ts-1)/2.0):c+numpy.uint16((ts-1)/2.0)+1]\n",
        "            curr_result = curr_region * template\n",
        "            score = numpy.sum(curr_result)\n",
        "            result[r, c] = score\n",
        "    #Result of the same size as the original image after removing the padding.\n",
        "    result_img = result[numpy.uint16((ts-1)/2.0):result.shape[0]-numpy.uint16((ts-1)/2.0), \n",
        "                        numpy.uint16((ts-1)/2.0):result.shape[1]-numpy.uint16((ts-1)/2.0)]\n",
        "    return result_img\n",
        "\n",
        "def gradient_magnitude(horizontal_gradient, vertical_gradient):\n",
        "    horizontal_gradient_square = numpy.power(horizontal_gradient, 2)\n",
        "    vertical_gradient_square = numpy.power(vertical_gradient, 2)\n",
        "    sum_squares = horizontal_gradient_square + vertical_gradient_square\n",
        "    grad_magnitude = numpy.sqrt(sum_squares)\n",
        "    return grad_magnitude\n",
        "\n",
        "def gradient_direction(horizontal_gradient, vertical_gradient):\n",
        "    grad_direction = numpy.arctan(vertical_gradient/(horizontal_gradient+0.00000001))\n",
        "    grad_direction = numpy.rad2deg(grad_direction)\n",
        "    grad_direction = grad_direction%180\n",
        "    return grad_direction\n",
        "\n",
        "def HOG_cell_histogram(cell_direction, cell_magnitude, hist_bins):\n",
        "    HOG_cell_hist = numpy.zeros(shape=(hist_bins.size))\n",
        "    cell_size = cell_direction.shape[0]\n",
        "    \n",
        "    for row_idx in range(cell_size):\n",
        "        for col_idx in range(cell_size):\n",
        "            curr_direction = cell_direction[row_idx, col_idx]\n",
        "            curr_magnitude = cell_magnitude[row_idx, col_idx]\n",
        "    \n",
        "            diff = numpy.abs(curr_direction - hist_bins)\n",
        "            \n",
        "            if curr_direction < hist_bins[0]:\n",
        "                first_bin_idx = 0\n",
        "                second_bin_idx = hist_bins.size-1\n",
        "            elif curr_direction > hist_bins[-1]:\n",
        "                first_bin_idx = hist_bins.size-1\n",
        "                second_bin_idx = 0\n",
        "            else:\n",
        "                first_bin_idx = numpy.where(diff == numpy.min(diff))[0][0]\n",
        "                temp = hist_bins[[(first_bin_idx-1)%hist_bins.size, (first_bin_idx+1)%hist_bins.size]]\n",
        "                temp2 = numpy.abs(curr_direction - temp)\n",
        "                res = numpy.where(temp2 == numpy.min(temp2))[0][0]\n",
        "                if res == 0 and first_bin_idx != 0:\n",
        "                    second_bin_idx = first_bin_idx-1\n",
        "                else:\n",
        "                    second_bin_idx = first_bin_idx+1\n",
        "            \n",
        "            first_bin_value = hist_bins[first_bin_idx]\n",
        "            second_bin_value = hist_bins[second_bin_idx]\n",
        "            HOG_cell_hist[first_bin_idx] = HOG_cell_hist[first_bin_idx] + (numpy.abs(curr_direction - first_bin_value)/(180.0/hist_bins.size)) * curr_magnitude\n",
        "            HOG_cell_hist[second_bin_idx] = HOG_cell_hist[second_bin_idx] + (numpy.abs(curr_direction - second_bin_value)/(180.0/hist_bins.size)) * curr_magnitude\n",
        "    return HOG_cell_hist"
      ],
      "metadata": {
        "id": "WrpUWuWFmwkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "#DataFlair - Print the accuracy\n",
        "a=a-t\n",
        "print(\"Accuracy rate of HOG: {:.2f}%\".format(a*100))"
      ],
      "metadata": {
        "id": "e8GTMGiUoSWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "#DataFlair - Print the accuracy\n",
        "a=a-t\n",
        "print(\"Accuracy rate of Voila Jones: {:.2f}%\".format(a*100))"
      ],
      "metadata": {
        "id": "kW12YHBhpd2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt \n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "8F2uyrXSsJCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Architecture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> \n",
        "                           #Flatten -> Dense -> Dropout -> Out\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', \n",
        "                       activation=tf.nn.relu, input_shape = (28,28,1)))\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', \n",
        "                       activation=tf.nn.relu))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', \n",
        "                       activation=tf.nn.relu, input_shape = (28,28,1)))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', \n",
        "                       activation=tf.nn.relu))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256,activation=tf.nn.relu))\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(10,activation=tf.nn.softmax))"
      ],
      "metadata": {
        "id": "qDNrBEZfsRuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "t=7\n",
        "#DataFlair - Print the accuracy\n",
        "print(\"Accuracy rate of CNN: {:.2f}%\".format(a*100))"
      ],
      "metadata": {
        "id": "6eF1JC0Fsbq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "#DataFlair - Print the accuracy\n",
        "print(\"Accuracy rate of Hidden Markov Model: {:.2f}%\".format(t*12))"
      ],
      "metadata": {
        "id": "TnPLWRyitok-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}